import json
import os

import streamlit as st
from dotenv import load_dotenv
from langchain_openai.chat_models import ChatOpenAI
from langgraph.checkpoint.memory import InMemorySaver
from pydantic import SecretStr
from pymilvus import MilvusClient

import db_tools
from prompts.PromptManager import PromptManager
from rag.milvus_helper import search_questions

load_dotenv()

if not os.environ.get("OPENAI_API_KEY") or not os.environ.get("OPENAI_API_BASE"):
    raise ValueError("OPENAI_API_KEY and OPENAI_API_BASE must be set")

config = {"configurable": {"thread_id": "1"}}

checkpointer = InMemorySaver()

from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, END

from typing import List, Dict, Any


def custom_append_only(left: List[Dict[str, Any]], right: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    è‡ªå®šä¹‰æ·»åŠ æ–¹æ³•ï¼Œåªå°†æ–°æ¶ˆæ¯è¿½åŠ åˆ°çŠ¶æ€ä¸­
    æ³¨æ„ï¼šleft å‚æ•°åŒ…å«å½“å‰çŠ¶æ€ä¸­çš„æ‰€æœ‰æ¶ˆæ¯
          right å‚æ•°åŒ…å«è¦æ·»åŠ çš„æ–°æ¶ˆæ¯
    """
    # å¦‚æœ right æ˜¯å•ä¸ªå­—å…¸ï¼Œåˆ™è½¬æ¢ä¸ºåˆ—è¡¨
    if not isinstance(right, list):
        right = [right]
    return left + right


class State(TypedDict):
    messages: Annotated[list, custom_append_only]
    pre_call_tolls: list


pre_call_tolls = []
graph_builder = StateGraph(State)
llm_with_tools = llm.bind_tools(tools)


def llm_call(state: State):
    print(state["messages"], flush=True)
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


from openai import OpenAI
import os


def get_message_role(msg_type: str) -> str:
    if msg_type == "human":
        return "user"
    elif msg_type == "ai":
        return "assistant"
    elif msg_type == "system":
        return "system"
    else:
        return msg_type


def openai_llm_call(state: State):
    client = OpenAI(
        # å¦‚æœæ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼API Keyæ›¿æ¢ï¼šapi_key="sk-xxx"
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    # dict_messages = []
    # for msg in state["messages"]:
    #     role =get_message_role(msg.type)
    #     content = msg.content
    #     dict_msg={
    #         "role":role,
    #         "content":content
    #     }
    #     if hasattr(msg,"tool_call"):
    #         dict_msg["tool_calls"] = msg.tool_call
    #     dict_messages.append(dict_msg)

    # dict_messages = [{"role": get_message_role(msg.type), "content": str(msg.content)} for msg in state["messages"] ]
    # print(dict_messages)
    dict_messages = state["messages"]
    completion = client.chat.completions.create(
        # model="qwen3-32b",
        model="qwen3-235b-a22b",
        messages=dict_messages,
        parallel_tool_calls=True,
        tools=db_tools.tools,
        stream=True,
    )
    reasoning_content = ""  # å®Œæ•´æ€è€ƒè¿‡ç¨‹
    answer_content = ""  # å®Œæ•´å›å¤
    tool_info = []  # å­˜å‚¨å·¥å…·è°ƒç”¨ä¿¡æ¯
    for chunk in completion:
        if not chunk.choices:
            print("\nUsage:")
            print(chunk.usage)
            continue

        delta = chunk.choices[0].delta
        if hasattr(delta, "content") and delta.content:
            print(delta.content, end="", flush=True)
            answer_content += delta.content
        # åªæ”¶é›†æ€è€ƒå†…å®¹
        if hasattr(delta, "reasoning_content") and delta.reasoning_content is not None:
            print(delta.reasoning_content, end="", flush=True)
            reasoning_content += delta.reasoning_content
        # å¤„ç†å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆæ”¯æŒå¹¶è¡Œå·¥å…·è°ƒç”¨ï¼‰
        if delta.tool_calls is not None:
            for tool_call in delta.tool_calls:
                index = tool_call.index  # å·¥å…·è°ƒç”¨ç´¢å¼•ï¼Œç”¨äºå¹¶è¡Œè°ƒç”¨

                # åŠ¨æ€æ‰©å±•å·¥å…·ä¿¡æ¯å­˜å‚¨åˆ—è¡¨
                while len(tool_info) <= index:
                    tool_info.append({})

                # æ”¶é›†å·¥å…·è°ƒç”¨IDï¼ˆç”¨äºåç»­å‡½æ•°è°ƒç”¨ï¼‰
                if tool_call.id:
                    tool_info[index]['id'] = tool_info[index].get('id', '') + tool_call.id

                if tool_call.function and tool_info[index].get("function") is None:
                    tool_info[index]["function"] = {}
                # æ”¶é›†å‡½æ•°åç§°ï¼ˆç”¨äºåç»­è·¯ç”±åˆ°å…·ä½“å‡½æ•°ï¼‰
                if tool_call.function and tool_call.function.name:
                    tool_info[index]["function"]['name'] = tool_info[index]["function"].get('name',
                                                                                            '') + tool_call.function.name

                # æ”¶é›†å‡½æ•°å‚æ•°ï¼ˆJSONå­—ç¬¦ä¸²æ ¼å¼ï¼Œéœ€è¦åç»­è§£æï¼‰
                if tool_call.function and tool_call.function.arguments:
                    tool_info[index]["function"]['arguments'] = tool_info[index]["function"].get('arguments',
                                                                                                 '') + tool_call.function.arguments
    print(f"\n" + "=" * 19 + "å·¥å…·è°ƒç”¨ä¿¡æ¯" + "=" * 19)
    if not tool_info:
        print("æ²¡æœ‰å·¥å…·è°ƒç”¨")
    else:
        print(tool_info)

    return {"messages": [{"role": "assistant", "content": answer_content, "tool_calls": tool_info}]}


def route_tools(
        state: State,
):
    """
    Use in the conditional_edge to route to the ToolNode if the last message
    has tool calls. Otherwise, route to the end.
    """
    if isinstance(state, list):
        ai_message = state[-1]
    elif messages := state.get("messages", []):
        ai_message = messages[-1]
    else:
        raise ValueError(f"No messages found in input state to tool_edge: {state}")
    print("route_tools ai_message", ai_message)
    if "tool_calls" in ai_message and len(ai_message["tool_calls"]) > 0:
        print("to tools")
        return "tools"
    print("to end")
    return END


from app_tool import BasicToolNode, ManualToolNode

graph_builder.add_node("llm_call", openai_llm_call)
tool_node = BasicToolNode(tools=tools)
graph_builder.add_node("tools", tool_node)
pre_tools_node = ManualToolNode(tools=tools)
graph_builder.add_node("pre_tools", pre_tools_node)

graph_builder.set_entry_point("pre_tools")
# graph_builder.set_entry_point("llm_call")
graph_builder.add_edge("pre_tools", "llm_call")
graph_builder.add_conditional_edges("llm_call", route_tools, {"tools": "tools", END: END}, )
graph_builder.add_edge("tools", "llm_call")
graph = graph_builder.compile()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="LLMå¯¹è¯åŠ©æ‰‹",
    page_icon="ğŸ’¬",
    layout="wide"
)

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []


def get_vector_store(URI="http://192.168.100.27:19530"):
    client = MilvusClient(uri=URI)
    return client


promptmanager = PromptManager("../background_prompts.md")


def build_prompt(question: str):
    prompt = """
## è§’è‰²
ä½ æ˜¯å…¬å¸å†…éƒ¨çš„è´¢åŠ¡åŠ©æ‰‹ï¼Œç²¾é€šè´¢åŠ¡æŠ¥è¡¨å’Œå‘ç¥¨ç¨åŠ¡çŸ¥è¯†ï¼ŒåŒæ—¶æ“…é•¿ä½¿ç”¨SQLè¯­å¥ã€‚
## ä»»åŠ¡
æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œç”Ÿæˆå¹¶æ‰§è¡Œç›¸åº”çš„mysqlè¯­å¥ã€‚ ç”Ÿæˆsqlè¯­å¥åï¼Œéœ€è¦è°ƒç”¨å·¥å…·æ‰§è¡Œsqlè¯­å¥ã€‚   
æŸ¥è¯¢å®Œsqlåï¼Œä½¿ç”¨ä¸€ä¸¤è¡Œå›å¤ç”¨æˆ·æ‰§è¡Œå®Œæˆå³å¯ï¼Œä¸è¦åœ¨å›å¤ä¸­åˆ—å‡ºè¯¦ç»†è®°å½•ã€‚
## æ³¨æ„äº‹é¡¹
æ³¨æ„é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å®Œæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬æ‰§è¡ŒsqlæŸ¥è¯¢ï¼Œè·å–è¡¨ç»“æ„ç­‰ã€‚   
æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œç®€æ´åœ°å›ç­”é—®é¢˜ï¼Œé¿å…æ— å…³è¾“å‡ºï¼›
## è¾“å‡ºæ ¼å¼
è¾“å‡ºç»™ç”¨æˆ·çš„å›ç­”ï¼Œè¯·éµå¾ªmarkdownè¯­æ³•ã€‚ 
"""

    entities = search_questions(question)

    hit_question = [entity['question_text'] for entity in entities]

    print("hit_question:", hit_question)
    entity = entities[0]
    category = entity['category']
    print("category:", category)
    category_prompt = promptmanager.get_prompt(category)
    prompt += ("\n## ä¸šåŠ¡èƒŒæ™¯\n")
    prompt += category_prompt

    examples = [
        {"question": entity['question_text'], "explain": entity['question_context'], "sql": entity['example_sql']} for
        entity in entities]
    from langchain.prompts import PromptTemplate, FewShotPromptTemplate
    example_template = """
    ç¤ºä¾‹é—®é¢˜: {question}
    é—®é¢˜åˆ†æ: {explain}
    ç¤ºä¾‹SQL: {sql}
    """
    example_prompt = PromptTemplate(
        input_variables=["question", "explain", "sql"],
        template=example_template,
    )
    prefix = """
## ç¤ºä¾‹é—®é¢˜å’ŒSQLè¯­å¥
"""
    examples_prompt = FewShotPromptTemplate(
        examples=examples,
        example_prompt=example_prompt,
        prefix=prefix,
        suffix="è¯·åˆ†æä¸šåŠ¡èƒŒæ™¯å’Œç¤ºä¾‹é—®é¢˜ï¼Œé€‰æ‹©å’Œç”¨æˆ·é—®é¢˜ç›¸å…³çš„ç¤ºä¾‹ï¼Œç”Ÿæˆæ»¡è¶³ç”¨æˆ·éœ€è¦çš„sqlï¼Œç„¶åè°ƒç”¨å·¥å…·æ‰§è¡Œã€‚å¦‚æœç¤ºä¾‹é—®é¢˜æ²¡æœ‰å’Œç”¨æˆ·é—®é¢˜ç›¸å…³çš„ï¼Œç›´æ¥å›å¤æ ¹æ®ç°æœ‰çŸ¥è¯†ï¼Œæ— æ³•å›ç­”ï¼ã€‚",
        example_separator="\n"  # ç¤ºä¾‹ä¹‹é—´çš„åˆ†éš”ç¬¦
    )

    prompt += examples_prompt.format(input=question)

    # if category == "ç§‘ç›®ä½™é¢è¡¨":
    #     tool_call = {
    #         "name": "get_table_schema",
    #         "args": {
    #             "table_name": "jd_account_balance_table"
    #         }
    #     }
    #     pre_call_tolls.append(tool_call)
    #     print("pre_call_tolls",pre_call_tolls)

    # prompt += f"ç¤ºä¾‹é—®é¢˜ï¼š{entity['question_text']}\n"
    # prompt += f"å¯¹åº”SQLè¯­å¥ï¼š{entity['example_sql']}\n\n"
    print("prompt:", prompt)
    return prompt


# æ¸…é™¤å¯¹è¯å‡½æ•°
def clear_chat():
    # åˆ é™¤session_stateä¸­çš„messages
    if "messages" in st.session_state:
        del st.session_state.messages
    st.session_state.chat_history = []


# é¡µé¢æ ‡é¢˜å’Œè¯´æ˜
st.title("ğŸ’¬ LLMå¯¹è¯åŠ©æ‰‹")

# æ˜¾ç¤ºæ¸…é™¤å¯¹è¯æŒ‰é’®
st.sidebar.button("æ¸…é™¤å¯¹è¯å†å²", on_click=clear_chat, type="primary")

# æ˜¾ç¤ºå¯¹è¯å†å²
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        for component in message["components"]:
            if component["type"] == "code":
                st.code(component["content"])
            elif component["type"] == "text":
                st.text(component["content"])
            elif component["type"] == "title":
                st.title(component["content"])
            elif component["type"] == "error":
                st.error(component["content"])
            elif component["type"] == "subheader":
                st.subheader(component["content"])
            elif component["type"] == "dataframe":
                st.dataframe(component["content"])
            elif component["type"] == "table":
                st.dataframe(component["content"])
            elif component["type"] == "markdown":
                st.markdown(component["content"])
            elif component["type"] == "image":
                st.image(component["content"])
            else:
                st.write(component["content"])

# å¤„ç†ç”¨æˆ·è¾“å…¥
if user_input := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):

    prompt = build_prompt(user_input)
    system_prompt = {"role": "system", "content": prompt}
    if "messages" not in st.session_state:
        st.session_state.messages = [system_prompt]

    # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
    st.session_state.messages.append({"role": "user", "content": user_input})

    # æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    with st.chat_message("user"):
        st.markdown(user_input)
        st.session_state.chat_history.append({"role": "user", "components": [{"type": "text", "content": user_input}]})

    with st.chat_message("assistant"):

        full_response = ""
        history_components = []
        # ä½¿ç”¨streamæ–¹æ³•æ›¿ä»£invokeï¼Œè·å–æµå¼è¾“å‡º
        for chunk in graph.stream({"messages": st.session_state.messages, "pre_call_tolls": pre_call_tolls},
                                  config=config):
            # æ¯ä¸ªchunkåŒ…å«å½“å‰æ­¥éª¤çš„ç»“æœ
            print("\n===== ä¸­é—´ç»“æœ =====")
            for key, value in chunk.items():
                print(f"{key}: {value}")
                if key == "tools":
                    messages = value["messages"]
                    for message in messages:
                        tool_name = message.get("name")
                        content = json.loads(message.get("content"))
                        st.markdown(f"### è°ƒç”¨å·¥å…·ï¼š{tool_name}")
                        if tool_name == "get_all_tables":
                            if "error" in content:
                                st.error(f"é”™è¯¯: {content['error']}")
                                history_components.append({"type": "error", "content": content['error']})
                            else:
                                st.write("æ•°æ®åº“è¡¨åˆ—è¡¨:")
                                history_components.append({"type": "text", "content": "æ•°æ®åº“è¡¨åˆ—è¡¨:"})
                                st.dataframe(content["tables"])
                                history_components.append({"type": "dataframe", "content": content['tables']})
                        elif tool_name == "get_table_schema":
                            if "error" in content:
                                st.error(f"è·å–ç»“æ„é”™è¯¯: {content['error']}")
                                history_components.append({"type": "error", "content": content['error']})
                            else:
                                st.code(content["schema"])
                                history_components.append({"type": "code", "content": content["schema"]})
                        elif tool_name == "get_query_data":
                            if "error" in content:
                                st.error(f"æŸ¥è¯¢é”™è¯¯: {content['error']}")
                                history_components.append({"type": "error", "content": content['error']})
                            else:
                                st.subheader("æŸ¥è¯¢ç»“æœ:")
                                history_components.append({"type": "text", "content": "æŸ¥è¯¢ç»“æœ:"})
                                st.dataframe(content["data"])
                                history_components.append({"type": "dataframe", "content": content["data"]})
                elif key == "llm_call":
                    messages = value["messages"]
                    for message in messages:
                        tool_calls = message.get("tool_calls")
                        if tool_calls is None or len(tool_calls) == 0:
                            st.markdown(message.get("content"))
                        else:
                            for tool_call in tool_calls:
                                func = tool_call["function"]
                                name = func["name"]
                                arguments = json.loads(func["arguments"])
                                if name == "get_query_data":
                                    st.write("æ‰§è¡ŒSQL:")
                                    st.code(arguments["sql"])
                                elif name == "get_table_schema":
                                    st.write(arguments["table_name"])
                else:
                    print(f"å…¶ä»–é”®: {key}")

        st.session_state.chat_history.append({"role": "assistant", "components": history_components})
